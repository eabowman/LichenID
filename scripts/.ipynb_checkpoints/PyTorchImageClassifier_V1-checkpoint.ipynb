{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c96d0ec-76ef-499e-b003-ca78b6bc5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full image classification pipeline using transfer learning and CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf473e-410b-413b-b70c-bd5ed5859ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch\n",
    "# %pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7750e5dd-011a-4f0b-843f-1d44933e2607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eefede5-aae9-4c37-9e4a-ca7cfd747ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your dataset\n",
    "data_dir = \"/Users/eabowman/Dropbox/LichenProject/dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392b6b09-efc1-40bf-9db6-171390d74d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad79ad0-0e1a-48e4-8b48-62b2cb581a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for valid image files inside subfolders\n",
    "base_dir = \"/Users/eabowman/Dropbox/LichenProject/dataset\"\n",
    "classes = os.listdir(base_dir)\n",
    "\n",
    "for cls in classes[:5]:  # Check first 5 folders\n",
    "    cls_path = os.path.join(base_dir, cls)\n",
    "    if os.path.isdir(cls_path):\n",
    "        print(f\"\\n{cls} contains:\")\n",
    "        print(os.listdir(cls_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb5db34-bfa3-4c09-91de-12a231c0e3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show which class folders are empty class\n",
    "for cls in os.listdir(base_dir):\n",
    "    cls_path = os.path.join(base_dir, cls)\n",
    "    if os.path.isdir(cls_path):\n",
    "        files = os.listdir(cls_path)\n",
    "        if not any(f.lower().endswith(('.jpg', '.jpeg', '.png', '.tif', '.tiff')) for f in files):\n",
    "            print(f\"⚠️ No valid images in: {cls_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094e5238-4f14-4e90-940a-54695775c74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that checks if a file has a valid image extension\n",
    "def is_valid_image(filename):\n",
    "    valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff', '.webp')\n",
    "    return filename.lower().endswith(valid_extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6e5a81-02a3-4f8d-b0f2-b6c0831b8881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = datasets.ImageFolder(\n",
    "    root=data_dir,\n",
    "    transform=transform,\n",
    "    is_valid_file=is_valid_image,  # optional, but robust\n",
    "    allow_empty=True  # prevents crashing due to empty folders\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db794af8-e636-4a84-99ff-a4456360f524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "# 80% training and 20% validation\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f328618-7f1e-4732-b754-17a89f876b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff9f0c6-7faf-4316-824d-336db2e81d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class names\n",
    "class_names = dataset.classes\n",
    "print(f\"Found {len(class_names)} species (classes).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a8fd89-322f-4d43-836f-aa6667ae3cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model using transfer learning on top of a CNN backbone\n",
    "weights = ResNet18_Weights.DEFAULT  # Use the latest available weights\n",
    "model = resnet18(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f295755-9639-4665-85de-0944b2abdfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model architecture to confirm it loaded\n",
    "print(model)\n",
    "# double-check that weights were applied\n",
    "print(weights.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b76d6a-f701-4d0a-9f1f-93d56e9de9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the final classification layer to match your number of classes\n",
    "num_classes = len(class_names)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e9b225-108c-477f-81a9-ff29f5707be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check final layer\n",
    "print(model.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42101228-59c0-4e9c-b2ee-e8a8e56dee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if PyTorch detects a GPU\n",
    "iprint(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72809f6-8dda-4958-829e-4185e7022e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to the right device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c39931-c39c-4ed4-a7cb-f8bf5669d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0216167c-39a1-4936-baea-f9bacc9465aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler\n",
    "exp_lr_scheduler = optim.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e796ad8d-8684-4c2c-bf01-d7b2ad2859b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data directory paths\n",
    "train_dir = f'{data_dir}/train'\n",
    "val_dir = f'{data_dir}/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a28be04-7d3f-429a-aca1-cab8e52c4bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "image_datasets = {\n",
    "    'train': datasets.ImageFolder(train_dir, data_transforms['train']),\n",
    "    'val': datasets.ImageFolder(val_dir, data_transforms['val'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90b7f0a-257d-4e7e-ad02-c3e53ead006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=32, shuffle=True, num_workers=2),\n",
    "    'val': DataLoader(image_datasets['val'], batch_size=32, shuffle=False, num_workers=2)\n",
    "}\n",
    "\n",
    "# And you can get the class names like this:\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a5531f-8f25-42ec-b56f-f141731752ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training model\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, device='cpu'):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluation mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            # Deep copy the model if it’s the best so far\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f\"\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "    print(f\"Best val Acc: {best_acc:.4f}\")\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79beea06-0af6-45d7-aba7-54b733813c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training loop or call train_model() function\n",
    "num_epochs = 25  # or however many you want\n",
    "\n",
    "model = train_model(model, dataloaders, criterion, optimizer, exp_lr_scheduler, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce79379-f4d2-4511-a847-54063a6816da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model\n",
    "# Load a local image and predict\n",
    "# Replace with your image path\n",
    "img_path = \"/Users/eabowman/Dropbox/LichenProject/test_images/tcm-23467-acarospora_rosulata.jpeg\"\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "# Preprocess it\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(img)\n",
    "input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "input_batch = input_batch.to(device)\n",
    "\n",
    "# Run the model\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "\n",
    "# Get top 5 predictions\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(f\"{imagenet_classes[top5_catid[i]]}: {top5_prob[i].item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
